{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulus\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "from functools import cmp_to_key\n",
    "from statistics import mean\n",
    "import gymnasium as gym\n",
    "from enum import Enum\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# __metaclass__ = type\n",
    "NO_NAME = \"SIMULUS_EVENT_NO_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clusterConfig.cluster import *\n",
    "from clusterConfig.job import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Schedulus:\n",
    "    def __init__(self, num_proc, backfill, path):\n",
    "        self.jobs = {}\n",
    "        self.schedule = []\n",
    "        self.waiting = []\n",
    "        self.running = []\n",
    "        self.backfill = backfill\n",
    "        self.path = path\n",
    "        self.stats = {}\n",
    "        self.cluster = Cluster(num_proc, num_proc, num_proc)\n",
    "        self.sim = simulus.simulator()\n",
    "\n",
    "    def __log(self, submitted, started, finished):\n",
    "        current_utilization = (\n",
    "            self.cluster.total - self.cluster.idle\n",
    "        ) / self.cluster.total\n",
    "        if self.sim.now not in self.stats:\n",
    "            self.stats[self.sim.now] = {\n",
    "                \"utilization\": current_utilization,\n",
    "                \"num_running_jobs\": len(self.running),\n",
    "            }\n",
    "        elif current_utilization > self.stats[self.sim.now][\"utilization\"]:\n",
    "            self.stats[self.sim.now][\"utilization\"] = current_utilization\n",
    "        if len(self.jobs) <= 100:\n",
    "            logger.debug(\"<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "            logger.debug(\"Time: \" + str(self.sim.now))\n",
    "            logger.debug(\"Utilization: \" + str(current_utilization))\n",
    "            logger.debug(\"------------------------------\")\n",
    "            logger.debug(\"Wait: \" + str(self.waiting))\n",
    "            logger.debug(\"Run: \" + str(self.running))\n",
    "            logger.debug(\"Schedule: \" + str(self.schedule))\n",
    "            logger.debug(\"------------------------------\")\n",
    "            logger.debug(\n",
    "                \"Total: \" + str(self.cluster.total) + \" Idle: \" + str(self.cluster.idle)\n",
    "            )\n",
    "            logger.debug(\"------------------------------\")\n",
    "            if submitted:\n",
    "                logger.debug(\"[Submit] \" + str(submitted))\n",
    "            if started:\n",
    "                logger.debug(\"[Start] \" + str(started))\n",
    "            if finished:\n",
    "                logger.debug(\"[Finish] \" + str(finished))\n",
    "            logger.debug(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\n\")\n",
    "\n",
    "    def __process_submit(self, job_id):\n",
    "        submitted = []\n",
    "        started = []\n",
    "\n",
    "        job = self.jobs[job_id]\n",
    "\n",
    "        if job.req_proc <= self.cluster.total:\n",
    "            job.submit()\n",
    "            self.waiting.append(job_id)\n",
    "            self.schedule.append(job_id)\n",
    "            submitted.append(job_id)\n",
    "\n",
    "            s_job = self.jobs[self.schedule[0]]\n",
    "\n",
    "            if self.cluster.allocate(s_job.req_proc):\n",
    "                self.__initiate_job(s_job.id)\n",
    "                started.append(s_job.id)\n",
    "            elif self.backfill != \"none\":\n",
    "                started.extend(self.__backfill(s_job.id))\n",
    "\n",
    "            self.__log(submitted, started, [])\n",
    "\n",
    "    def __process_end(self, job_id):\n",
    "        started = []\n",
    "        finished = []\n",
    "\n",
    "        job = self.jobs[job_id]\n",
    "\n",
    "        job.finish(self.sim.now)\n",
    "        self.cluster.release(job.req_proc)\n",
    "        self.running.remove(job_id)\n",
    "        finished.append(job_id)\n",
    "\n",
    "        do_backfill = self.backfill != \"none\" and len(self.schedule) > 0\n",
    "\n",
    "        while self.schedule and self.cluster.allocate(\n",
    "            self.jobs[self.schedule[0]].req_proc\n",
    "        ):\n",
    "            next_job_id = self.schedule[0]\n",
    "            self.__initiate_job(next_job_id)\n",
    "            started.append(next_job_id)\n",
    "            do_backfill = False\n",
    "\n",
    "        if do_backfill:\n",
    "            started.extend(self.__backfill(self.jobs[self.schedule[0]].id))\n",
    "\n",
    "        self.__log([], started, finished)\n",
    "\n",
    "    # https://www.cse.huji.ac.il/~perf/ex11.html\n",
    "    def __backfill(self, job_id):\n",
    "        job = self.jobs[job_id]\n",
    "\n",
    "        proc_pool = self.cluster.idle\n",
    "        idle_procs = self.cluster.idle\n",
    "        extra_procs = 0\n",
    "        shadow_time = -1\n",
    "\n",
    "        jobs_exp_end = []\n",
    "        for r_job_id in self.running:\n",
    "            # print('Job ' + str(r_job_id) + ' has been running for ' + str(self.sim.now - self.jobs[r_job_id].start_time) + ' seconds')\n",
    "            # print('Job ' + str(r_job_id) + ' is expected to end at time ' + str(self.jobs[r_job_id].start_time + self.jobs[r_job_id].req_time))\n",
    "            jobs_exp_end.append(\n",
    "                (\n",
    "                    r_job_id,\n",
    "                    self.jobs[r_job_id].start_time + self.jobs[r_job_id].req_time,\n",
    "                )\n",
    "            )\n",
    "        jobs_exp_end.sort(key=lambda tup: tup[1])\n",
    "\n",
    "        for job_exp_end in jobs_exp_end:\n",
    "            if proc_pool < job.req_proc:\n",
    "                proc_pool += self.jobs[job_exp_end[0]].req_proc\n",
    "            if proc_pool >= job.req_proc:\n",
    "                shadow_time = job_exp_end[1]\n",
    "                extra_procs = proc_pool - job.req_proc\n",
    "\n",
    "        started = []\n",
    "\n",
    "        for w_job_id in self.waiting[1:].copy():\n",
    "            # Condition 1: It uses no more than the currently available processors, and is expected to terminate by the shadow time.\n",
    "            if self.sim.now + self.jobs[\n",
    "                w_job_id\n",
    "            ].req_time < shadow_time and self.cluster.allocate(\n",
    "                self.jobs[w_job_id].req_proc\n",
    "            ):\n",
    "                self.__initiate_job(w_job_id)\n",
    "                started.append(w_job_id)\n",
    "            # Condition 2: It uses no more than the currently available processors, and also no more than the extra processors.\n",
    "            elif self.jobs[w_job_id].req_proc <= extra_procs and self.cluster.allocate(\n",
    "                self.jobs[w_job_id].req_proc\n",
    "            ):\n",
    "                self.__initiate_job(w_job_id)\n",
    "                extra_procs -= self.jobs[w_job_id].req_proc\n",
    "                started.append(w_job_id)\n",
    "\n",
    "        return started\n",
    "\n",
    "    def __initiate_job(self, job_id):\n",
    "        job = self.jobs[job_id]\n",
    "\n",
    "        job.start(self.sim.now)\n",
    "        self.sim.sched(self.__process_end, job_id, offset=job.run)\n",
    "        self.waiting.remove(job_id)\n",
    "        self.schedule.remove(job_id)\n",
    "        self.running.append(job_id)\n",
    "\n",
    "    def add_job(self, job: Job):\n",
    "        if job.id in self.jobs.keys():\n",
    "            raise ValueError(\"Job ID already exists in workload\")\n",
    "        else:\n",
    "            self.jobs[int(job.id)] = job\n",
    "            self.sim.sched(self.__process_submit, job.id, until=job.submit_time)\n",
    "\n",
    "    def read_jobs(self, path):\n",
    "        self.jobs = {}\n",
    "\n",
    "        with open(path) as job_file:\n",
    "            for trace_line in job_file:\n",
    "                # Find string before ';', then split that on whitespace to find trace fields\n",
    "                job_fields = trace_line.split(\";\", 1)[0].split()\n",
    "\n",
    "                if job_fields and float(job_fields[3]) != -1:\n",
    "                    self.jobs[int(job_fields[0])] = Job(\n",
    "                        id=int(job_fields[0]),\n",
    "                        submit_time=float(job_fields[1]),\n",
    "                        wait=float(job_fields[2]),\n",
    "                        run=float(job_fields[3]),\n",
    "                        used_proc=int(job_fields[4]),\n",
    "                        used_ave_cpu=float(job_fields[5]),\n",
    "                        used_mem=float(job_fields[6]),\n",
    "                        req_proc=int(job_fields[7])\n",
    "                        if int(job_fields[7]) != -1\n",
    "                        else int(job_fields[4]),\n",
    "                        req_time=float(job_fields[8]),\n",
    "                        req_mem=float(job_fields[9]),\n",
    "                        status=int(job_fields[10]),\n",
    "                        user_id=int(job_fields[11]),\n",
    "                        group_id=int(job_fields[12]),\n",
    "                        num_exe=int(job_fields[13]),\n",
    "                        num_queue=int(job_fields[14]),\n",
    "                        num_part=int(job_fields[15]),\n",
    "                        num_pre=int(job_fields[16]),\n",
    "                        think_time=int(job_fields[17]),\n",
    "                        start_time=-1,\n",
    "                        end_time=-1,\n",
    "                        score=0,\n",
    "                        state=0,\n",
    "                        happy=-1,\n",
    "                        est_start=-1,\n",
    "                    )\n",
    "\n",
    "    def get_peek_name(self):\n",
    "        if len(self.sim._eventlist) > 0:\n",
    "            x, e = self.sim._eventlist.pqueue.peek()\n",
    "            return e.name\n",
    "        else:\n",
    "            return NO_NAME\n",
    "\n",
    "    def get_peek_time(self):\n",
    "        return self.sim.peek()\n",
    "\n",
    "    def get_state(self):\n",
    "        # get running jobs remaining time and req_proc\n",
    "        running_jobs = []\n",
    "        for job_id in self.running:\n",
    "            job = self.jobs[job_id]\n",
    "            running_jobs.append(\n",
    "                (job_id, job.req_proc, job.run - (self.sim.now - job.start_time))\n",
    "            )\n",
    "        # get waiting jobs\n",
    "        waiting_job = []\n",
    "        for job_id in self.waiting:\n",
    "            job = self.jobs[job_id]\n",
    "            waiting_job.append((job_id, job.req_proc, job.run))\n",
    "        # get schedule jobs\n",
    "        schedule_job = []\n",
    "        for job_id in self.schedule:\n",
    "            job = self.jobs[job_id]\n",
    "            schedule_job.append((job_id, job.req_proc, job.run))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {\"running\": running_jobs, \"waiting\": waiting_job, \"schedule\": schedule_job}\n",
    "    \n",
    "    def one_step(self):\n",
    "        self.sim.step()\n",
    "\n",
    "    def get_now(self):\n",
    "        return self.sim.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUType(Enum):\n",
    "    A40 = 0\n",
    "    RTX_2080Ti = 1\n",
    "    RTX_TITAN = 2\n",
    "    TITAN_Xp = 3\n",
    "    TITAN_V = 4\n",
    "    GTX_1080 = 5\n",
    "    TITAN_X = 6\n",
    "    M40 = 7\n",
    "\n",
    "class NextEventType(Enum):\n",
    "    Submit = 0\n",
    "    Finish = 1\n",
    "    Other = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterEnv(gym.Env):\n",
    "    def __init__(self, job_file_path: str, cluster_config_path: str):\n",
    "        self.job_file_path = pathlib.Path(job_file_path)\n",
    "        self.cluster_config_path = pathlib.Path(cluster_config_path)\n",
    "\n",
    "        # read cluster_config_path as json\n",
    "        with open(self.cluster_config_path) as f:\n",
    "            self.cluster_config = json.load(f)\n",
    "            # transfer to GPUType\n",
    "            for gpu_type in GPUType:\n",
    "                self.gpu_type_proc_num = self.cluster_config[\"proc_num\"][gpu_type.name]\n",
    "\n",
    "        # read job_file_path as swf a.k.a. csv\n",
    "        self.jobs = {}\n",
    "        self.job_id_in_order = []\n",
    "        self.next_step_is = NextEventType.Submit\n",
    "\n",
    "        # construct cluster\n",
    "        self.cluster = {\n",
    "            gpu_type: Schedulus(self.gpu_type_proc_num[gpu_type.name], \"easy\", \"\")\n",
    "            for gpu_type in GPUType\n",
    "        }\n",
    "\n",
    "        # make action space\n",
    "        self.gpu_type_num = len(GPUType)\n",
    "        self.action_space = gym.spaces.Discrete(2 * self.gpu_type_num)\n",
    "        self._action_to_gpu_type = {}\n",
    "        for i, gpu_type in enumerate(GPUType):\n",
    "            self._action_to_gpu_type[i] = gpu_type\n",
    "            self._action_to_gpu_type[i + self.gpu_type_num] = gpu_type\n",
    "\n",
    "        # next submit job timestamp\n",
    "        self.next_submit_t = 0\n",
    "        self.next_submit_job_id = 0\n",
    "\n",
    "    def _get_obs(self):\n",
    "        state = {}\n",
    "        for gpu_type in GPUType:\n",
    "            state[gpu_type] = self.cluster[gpu_type].get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        action_gpu = self._action_to_gpu_type[action]\n",
    "        # if next step is submit the job\n",
    "        if action < self.gpu_type_num:\n",
    "            self.cluster[action_gpu].add_job(self.jobs[self.next_submit_job_id])\n",
    "            if self.job_id_in_order:\n",
    "                self.next_submit_job_id = self.job_id_in_order.pop(0)\n",
    "        # if next step in finish the job\n",
    "        else:\n",
    "            self.cluster[action_gpu].one_step()\n",
    "\n",
    "        # make steps until next step is finish before next submit time\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'cluster'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info.\n",
      "\u001b[1;31mSome of the following files found in the working directory may have prevented the Kernel from starting. Consider renaming them.\n",
      "\u001b[1;31mFile(s): <a href='file:///c%3A/Users/ottoz/GpuSim/types/__init__.py?line=1'>~\\types\\__init__.py</a> might need to be renamed.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/JupyterKernelStartFailureOverrideReservedName'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "ClusterEnv(\n",
    "    job_file_path=\"data/cluster/workload_1.csv\",\n",
    "    cluster_config_path=\"example_cluster.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schedulus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
